{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4775914",
   "metadata": {},
   "source": [
    "# Prepare custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7c1d31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 wngfra.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from bidict import bidict\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class Texture:\n",
    "    \"\"\" Create a bidict from a texture name list.\"\"\"\n",
    "\n",
    "    def __init__(self, texture_names):\n",
    "        self.texture_by_id = bidict()\n",
    "        for i, tn in enumerate(set(texture_names)):\n",
    "            self.texture_by_id[tn] = i\n",
    "\n",
    "    def get_id(self, texture_name: str):\n",
    "        return self.texture_by_id[texture_name]\n",
    "\n",
    "    def get_name(self, texture_id: int):\n",
    "        return self.texture_by_id.inverse[texture_id]\n",
    "\n",
    "\n",
    "class TacDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.filelist = [y for x in os.walk(\n",
    "            root_dir) for y in glob.glob(os.path.join(x[0], '*.csv'))]\n",
    "        self.params = [(0.0, 0.0)] * len(self.filelist)\n",
    "        self.texture_names = []\n",
    "        for i, filename in enumerate(self.filelist):\n",
    "            basename = os.path.basename(filename)\n",
    "            namegroups = basename.split('_')\n",
    "\n",
    "            self.texture_names.append(namegroups[0])\n",
    "            self.params[i] = [int(re.search(r\"\\d+\", namegroups[1]).group(0)),\n",
    "                              float(re.search(r\"[-+]?\\d+\", namegroups[2]).group(0))]\n",
    "        self.textures = Texture(self.texture_names)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.filelist[index]\n",
    "        rawdata  = np.genfromtxt(filename, delimiter=',', skip_header=1)\n",
    "        tacdata  = rawdata[:, 3:]\n",
    "        texture_name = self.texture_names[index]\n",
    "        if self.transform:\n",
    "            tacdata = self.transform(tacdata)\n",
    "        return tacdata, self.params[index], self.textures.get_id(texture_name)\n",
    "    \n",
    "    def count_class(self):\n",
    "        return len(set(self.texture_names))\n",
    "\n",
    "    def get_texture_name(self, texture_id):\n",
    "        return self.textures.get_name(texture_id)\n",
    "\n",
    "    \n",
    "\"\"\" Custom transforms \"\"\"\n",
    "\n",
    "class Normalize(object):\n",
    "    def __init__(self, axis=0):\n",
    "        self.axis = axis\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return (sample - np.mean(sample, keepdims=True)) / np.std(sample, keepdims=True)\n",
    "\n",
    "transform = transforms.Compose([Normalize(axis=1)])\n",
    "ds = TacDataset('data', transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefdc57b",
   "metadata": {},
   "source": [
    "# Visualize raw data in time and frequency domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f0cd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numpy.fft import fft\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "\n",
    "def plot2(i, item):\n",
    "    x, param, label = item[0], item[1], item[2]\n",
    "    \n",
    "    plt.plot(x)\n",
    "    title = ds.get_texture_name(label)\n",
    "    plt.suptitle(\"{} @ {}count and {}mm/s\".format(title, param[0], param[1]))\n",
    "    plt.show()\n",
    "\n",
    "for i, item in enumerate(ds):\n",
    "    plot2(i, item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3e460",
   "metadata": {},
   "source": [
    "# Compress data with Tucker decomposition\n",
    "1. Compute covariance matrix for each multi-channel frequency series\n",
    "2. Stack covariance matrix into a 3D covariance tensor $T \\in \\mathbb{R}^{C \\times C \\times N}$\n",
    "3. Use core tensor $\\mathcal{G}$ of the Tucker decomposition $T = \\mathcal{G} \\times_1 U_1 \\times_2 U_2 \\times_3 U_3$ as a compressed representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb854774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorly as tl\n",
    "from numpy.fft import fft\n",
    "from skfda import FDataGrid\n",
    "from skfda.representation import basis\n",
    "from sklearn.decomposition import PCA\n",
    "from tensorly.decomposition import non_negative_tucker, tucker\n",
    "\n",
    "fd_basis = basis.Fourier([0, 2 * np.pi], n_basis=17, period=1)\n",
    "\n",
    "df0 = pd.DataFrame(labels, columns=[\"texture\"])\n",
    "df1 = pd.DataFrame(params, columns=[\"pressure\", \"speed\"])\n",
    "\n",
    "def basis_expand(data):\n",
    "    ''' Compute covariance matrix with functional basis decomposition.'''\n",
    "    fd = FDataGrid(data.T).to_basis(fd_basis)\n",
    "    coeffs = fd.coefficients.squeeze().T\n",
    "    return coeffs.flatten(\"F\")\n",
    "\n",
    "coeff_array = []\n",
    "params = []\n",
    "labels = []\n",
    "\n",
    "for i, (sample, param, label) in enumerate(ds):\n",
    "    coeffs = basis_expand(sample)\n",
    "    coeff_array.append(coeffs)\n",
    "    params.append(param)\n",
    "    labels.append(ds.get_texture_name(label))\n",
    "    \n",
    "# Split trainset and testset\n",
    "train_ratio = 0.5\n",
    "index_array = np.asarray(df0[~df0[\"texture\"].str.contains(\"Board\")].index)\n",
    "count = int(len(index_array) * train_ratio)\n",
    "np.random.shuffle(index_array)\n",
    "train_ids = index_array[:count]\n",
    "test_ids = index_array[count:]\n",
    "\n",
    "covM = np.cov(np.asarray(coeff_array))\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(covM[train_ids, :])\n",
    "principalComponents = pca.transform(covM)\n",
    "\n",
    "df2 = pd.DataFrame(principalComponents, columns=[\"x1\", \"x2\", \"x3\"])\n",
    "df  = pd.concat([df0, df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9add7139",
   "metadata": {},
   "source": [
    "# Visualize compressed core tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ccb555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "shift = None\n",
    "\n",
    "textures = df[\"texture\"].unique()\n",
    "cmap = plt.cm.get_cmap(\"plasma\", len(textures))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "for i, texture in enumerate(textures):\n",
    "    X = df.loc[df[\"texture\"] == texture]\n",
    "    # plot core vectors\n",
    "    xs, ys, zs = X[\"x1\"], X[\"x2\"], X[\"x3\"]\n",
    "    if shift is not None:\n",
    "        xs, ys, zs = shift(xs), shift(ys), shift(zs)\n",
    "    ax.scatter(xs, ys, zs, s=20, c=np.tile(cmap(i), (len(xs), 1)))\n",
    "ax.legend(textures)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d711f36",
   "metadata": {},
   "source": [
    "# Construct RNN-AutoEncoder (RAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3e9ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\" Recurent Variational Autoencoder \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, device, dropout=0.3):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.device = device\n",
    "        \n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, output_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        packed_in = pack_padded_sequence(x[0].to(self.device), x[1].cpu().numpy(), batch_first=True)\n",
    "        rnn_out, self.hidden = self.rnn(packed_in)\n",
    "        x_in = self.hidden[-1].squeeze()\n",
    "        mu = self.fc_mu(x_in)\n",
    "        var = self.fc_var(x_in)\n",
    "        \n",
    "        return mu\n",
    "    \n",
    "    def init_hidden(self, batch_dim):\n",
    "        return (torch.zeros(self.n_layers, batch_dim, self.hidden_dim, device=self.device),\n",
    "                torch.zeros(self.n_layers, batch_dim, self.hidden_dim, device=self.device))\n",
    "\n",
    "\n",
    "class RVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, encoding_dim, extra_dim, output_dim, n_layers, device):\n",
    "        super(RVAE, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        self.encoder = Encoder(input_dim, hidden_dim, encoding_dim, n_layers, device)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encode(x[:2])\n",
    "        # x_in = torch.hstack([encoded, x[2].to(self.device)])\n",
    "        y = self.classifier(encoded)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "\"\"\" Custom collate functions\"\"\"\n",
    "\n",
    "class PadSequence(object):\n",
    "    def __call__(self, batch):\n",
    "        # Each element in \"batch\" is a tuple (data, label).\n",
    "        # Sort the batch in the descending order\n",
    "        sorted_batch = sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
    "        # Get each sequence and pad it\n",
    "        sequences = [torch.tensor(x[0], dtype=torch.float) for x in sorted_batch]\n",
    "        sequences_padded = pad_sequence(\n",
    "            sequences, batch_first=True)\n",
    "        # Store the length of each sequence\n",
    "        lengths = torch.tensor([len(x) for x in sequences])\n",
    "        params = torch.tensor(list(map(lambda x: x[1], sorted_batch)), dtype=torch.float)\n",
    "        labels = torch.tensor(list(map(lambda x: x[2], sorted_batch)))\n",
    "        return sequences_padded, lengths, params, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a98b95",
   "metadata": {},
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be8da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 10\n",
    "INPUT_DIM = 16\n",
    "NUM_CLASS = ds.count_class()\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "train_loader = DataLoader(ds, batch_size=BATCH_SIZE, collate_fn=PadSequence(), num_workers=6, shuffle=True)\n",
    "rvae = RVAE(input_dim=INPUT_DIM, hidden_dim=16, encoding_dim=3, extra_dim=2, output_dim=NUM_CLASS, n_layers=2, device=device)\n",
    "loss_list = []\n",
    "\n",
    "def train_once(x, y, model, optimizer, criterion):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(x)\n",
    "    target = y.to(device)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "    \n",
    "def train_model(data_loader, model):\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # loss_list = []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for i, (batch, lengths, params, targets) in enumerate(data_loader):\n",
    "            loss = train_once((batch, lengths, params), targets, model, optimizer, criterion)\n",
    "            running_loss += loss\n",
    "            loss_list.append(loss)\n",
    "            \n",
    "            if i % 10 == 9:\n",
    "                print('Epoch {}, {:.2f}% - loss: {:.6f}'.format(epoch + 1, 100.0 * (i + 1.0) / len(data_loader), running_loss / 10))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "    print(\"Training finished.\")\n",
    "    plt.figure()\n",
    "    plt.plot(loss_list)\n",
    "    plt.title(\"Training Recurrent Autoencoder\")\n",
    "    plt.xlabel(\"Run\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "train_model(train_loader, rvae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
